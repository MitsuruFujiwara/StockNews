{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結果の確認  \n",
    "グリッドサーチ後の各モデルの精度を比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('data.h5', key='test_selected', mode='r')\n",
    "X, Y = np.array(df.drop('Class', axis=1)), np.array(df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_t = pd.read_hdf('data.h5', key='train_selected', mode='r')\n",
    "X_t, Y_t = np.array(df_t.drop('Class', axis=1)), np.array(df_t['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = joblib.load('lr.pkl') \n",
    "mlp = joblib.load('mlp.pkl') \n",
    "dt = joblib.load('dt.pkl') \n",
    "svm = joblib.load('svm.pkl')\n",
    "xgb = joblib.load('xgb.pkl')\n",
    "rf = joblib.load('rf.pkl')\n",
    "dnn_ae3=load_model('DNN_ae3.h5')\n",
    "dnn_ae4=load_model('DNN_ae4.h5')\n",
    "dnn_ae5=load_model('DNN_ae5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnn_ae3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "dnn_ae4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "dnn_ae5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの加重平均スコアを集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 992/1610 [=================>............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model=[lr, mlp, dt, svm, xgb, rf]\n",
    "model_dnn=[dnn_ae3, dnn_ae4, dnn_ae5]\n",
    "model_name= ['lr', 'mlp', 'dt', 'svm', 'xgb', 'rf']\n",
    "model_name_dnn = ['dnn3', 'dnn4', 'dnn5']\n",
    "dnn_map = {0:-1, 1:0, 2:1}\n",
    "\n",
    "result_weighted={}\n",
    "result_m={}\n",
    "result_z={}\n",
    "result_p={}\n",
    "for s, t in zip(model, model_name):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, s.predict(X), average='weighted')\n",
    "    res_model['Precision Score'] = precision_score(Y, s.predict(X), average='weighted')\n",
    "    res_model['Recall Score'] = recall_score(Y, s.predict(X), average='weighted')\n",
    "    \n",
    "    res_model['Train F1']=f1_score(Y_t, s.predict(X_t), average='weighted')\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, s.predict(X_t), average='weighted')\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, s.predict(X_t), average='weighted')\n",
    "\n",
    "    result_weighted[t] = res_model\n",
    "    \n",
    "for s, t in zip(model_dnn, model_name_dnn):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average='weighted')\n",
    "    res_model['Precision Score'] = precision_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average='weighted')\n",
    "    res_model['Recall Score'] = recall_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average='weighted')\n",
    "\n",
    "    res_model['Train F1']=f1_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average='weighted')\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average='weighted')\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average='weighted')\n",
    "\n",
    "    result_weighted[t] = res_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの-1ラベルのスコアを集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 960/1610 [================>.............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "for s, t in zip(model, model_name):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, s.predict(X), average=None)[0]\n",
    "    res_model['Precision Score'] = precision_score(Y, s.predict(X), average=None)[0]\n",
    "    res_model['Recall Score'] = recall_score(Y, s.predict(X), average=None)[0]\n",
    "    \n",
    "    res_model['Train F1']=f1_score(Y_t, s.predict(X_t), average=None)[0]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, s.predict(X_t), average=None)[0]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, s.predict(X_t), average=None)[0]\n",
    "\n",
    "    result_m[t] = res_model\n",
    "    \n",
    "for s, t in zip(model_dnn, model_name_dnn):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[0]\n",
    "    res_model['Precision Score'] = precision_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[0]\n",
    "    res_model['Recall Score'] = recall_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[0]\n",
    "\n",
    "    res_model['Train F1']=f1_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[0]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[0]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[0]\n",
    "\n",
    "    result_m[t] = res_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの0ラベルのスコアを集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 896/1610 [===============>..............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "for s, t in zip(model, model_name):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, s.predict(X), average=None)[1]\n",
    "    res_model['Precision Score'] = precision_score(Y, s.predict(X), average=None)[1]\n",
    "    res_model['Recall Score'] = recall_score(Y, s.predict(X), average=None)[1]\n",
    "    \n",
    "    res_model['Train F1']=f1_score(Y_t, s.predict(X_t), average=None)[1]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, s.predict(X_t), average=None)[1]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, s.predict(X_t), average=None)[1]\n",
    "\n",
    "    result_z[t] = res_model\n",
    "    \n",
    "for s, t in zip(model_dnn, model_name_dnn):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[1]\n",
    "    res_model['Precision Score'] = precision_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[1]\n",
    "    res_model['Recall Score'] = recall_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[1]\n",
    "\n",
    "    res_model['Train F1']=f1_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[1]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[1]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[1]\n",
    "\n",
    "    result_z[t] = res_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの+1ラベルのスコアを集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/fujiwara/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 928/1610 [================>.............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "for s, t in zip(model, model_name):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, s.predict(X), average=None)[2]\n",
    "    res_model['Precision Score'] = precision_score(Y, s.predict(X), average=None)[2]\n",
    "    res_model['Recall Score'] = recall_score(Y, s.predict(X), average=None)[2]\n",
    "    \n",
    "    res_model['Train F1']=f1_score(Y_t, s.predict(X_t), average=None)[2]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, s.predict(X_t), average=None)[2]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, s.predict(X_t), average=None)[2]\n",
    "\n",
    "    result_p[t] = res_model\n",
    "    \n",
    "for s, t in zip(model_dnn, model_name_dnn):\n",
    "    res_model = {}\n",
    "    res_model['F1']=f1_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[2]\n",
    "    res_model['Precision Score'] = precision_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[2]\n",
    "    res_model['Recall Score'] = recall_score(Y, pd.Series(s.predict_classes(X)).map(dnn_map), average=None)[2]\n",
    "\n",
    "    res_model['Train F1']=f1_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[2]\n",
    "    res_model['Train Precision Score'] = precision_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[2]\n",
    "    res_model['Train Recall Score'] = recall_score(Y_t, pd.Series(s.predict_classes(X_t)).map(dnn_map), average=None)[2]\n",
    "\n",
    "    result_p[t] = res_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果を保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968825</td>\n",
       "      <td>0.997658</td>\n",
       "      <td>0.876640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943925</td>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.780374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dnn3      dnn4  dnn5        dt   lr       mlp  \\\n",
       "F1                     0.156250  0.083333   0.0  0.097561  0.0  0.108108   \n",
       "Precision Score        0.500000  0.166667   0.0  0.142857  0.0  0.200000   \n",
       "Recall Score           0.092593  0.055556   0.0  0.074074  0.0  0.074074   \n",
       "Train F1               1.000000  1.000000   1.0  0.565789  0.0  1.000000   \n",
       "Train Precision Score  1.000000  1.000000   1.0  0.955556  0.0  1.000000   \n",
       "Train Recall Score     1.000000  1.000000   1.0  0.401869  0.0  1.000000   \n",
       "\n",
       "                             rf       svm       xgb  \n",
       "F1                     0.092308  0.179487  0.036364  \n",
       "Precision Score        0.272727  0.291667  1.000000  \n",
       "Recall Score           0.055556  0.129630  0.018519  \n",
       "Train F1               0.968825  0.997658  0.876640  \n",
       "Train Precision Score  0.995074  1.000000  1.000000  \n",
       "Train Recall Score     0.943925  0.995327  0.780374  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_m = pd.DataFrame(result_m)\n",
    "result_z = pd.DataFrame(result_z)\n",
    "result_p = pd.DataFrame(result_p)\n",
    "result_weighted = pd.DataFrame(result_weighted)\n",
    "result_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.814696</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.815287</td>\n",
       "      <td>0.779832</td>\n",
       "      <td>0.824261</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.814696</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.823161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.706371</td>\n",
       "      <td>0.709859</td>\n",
       "      <td>0.705234</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.701058</td>\n",
       "      <td>0.695015</td>\n",
       "      <td>0.706371</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>0.703209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.950943</td>\n",
       "      <td>0.966038</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.913208</td>\n",
       "      <td>0.992453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896816</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990283</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>0.962659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815202</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981575</td>\n",
       "      <td>0.999148</td>\n",
       "      <td>0.928006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dnn3      dnn4      dnn5        dt        lr  \\\n",
       "F1                     0.814696  0.812903  0.815287  0.779832  0.824261   \n",
       "Precision Score        0.706371  0.709859  0.705234  0.703030  0.701058   \n",
       "Recall Score           0.962264  0.950943  0.966038  0.875472  1.000000   \n",
       "Train F1               1.000000  1.000000  1.000000  0.896816  0.842975   \n",
       "Train Precision Score  1.000000  1.000000  1.000000  0.815202  0.728571   \n",
       "Train Recall Score     1.000000  1.000000  1.000000  0.996590  1.000000   \n",
       "\n",
       "                            mlp        rf       svm       xgb  \n",
       "F1                     0.782178  0.814696  0.800000  0.823161  \n",
       "Precision Score        0.695015  0.706371  0.711765  0.703209  \n",
       "Recall Score           0.894340  0.962264  0.913208  0.992453  \n",
       "Train F1               1.000000  0.990283  0.999574  0.962659  \n",
       "Train Precision Score  1.000000  0.981575  0.999148  0.928006  \n",
       "Train Recall Score     1.000000  0.999147  1.000000  1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dnn3      dnn4      dnn5        dt   lr       mlp  \\\n",
       "F1                     0.030303  0.031250  0.057971  0.075949  0.0  0.052632   \n",
       "Precision Score        0.142857  0.200000  0.200000  0.150000  0.0  0.117647   \n",
       "Recall Score           0.016949  0.016949  0.033898  0.050847  0.0  0.033898   \n",
       "Train F1               1.000000  1.000000  1.000000  0.543689  0.0  1.000000   \n",
       "Train Precision Score  1.000000  1.000000  1.000000  0.976744  0.0  1.000000   \n",
       "Train Recall Score     1.000000  1.000000  1.000000  0.376682  0.0  1.000000   \n",
       "\n",
       "                             rf       svm       xgb  \n",
       "F1                     0.000000  0.082192  0.032258  \n",
       "Precision Score        0.000000  0.214286  0.333333  \n",
       "Recall Score           0.000000  0.050847  0.016949  \n",
       "Train F1               0.967890  1.000000  0.890547  \n",
       "Train Precision Score  0.990610  1.000000  1.000000  \n",
       "Train Recall Score     0.946188  1.000000  0.802691  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.598201</td>\n",
       "      <td>0.586675</td>\n",
       "      <td>0.580612</td>\n",
       "      <td>0.572499</td>\n",
       "      <td>0.577855</td>\n",
       "      <td>0.572011</td>\n",
       "      <td>0.584336</td>\n",
       "      <td>0.599316</td>\n",
       "      <td>0.587314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision Score</th>\n",
       "      <td>0.588934</td>\n",
       "      <td>0.552679</td>\n",
       "      <td>0.525627</td>\n",
       "      <td>0.536686</td>\n",
       "      <td>0.491483</td>\n",
       "      <td>0.534180</td>\n",
       "      <td>0.534168</td>\n",
       "      <td>0.574102</td>\n",
       "      <td>0.687875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall Score</th>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.632275</td>\n",
       "      <td>0.701058</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.701058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803905</td>\n",
       "      <td>0.614168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984329</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>0.941237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Precision Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856233</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984620</td>\n",
       "      <td>0.999379</td>\n",
       "      <td>0.947547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Recall Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831677</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.999379</td>\n",
       "      <td>0.943478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dnn3      dnn4      dnn5        dt        lr  \\\n",
       "F1                     0.598201  0.586675  0.580612  0.572499  0.577855   \n",
       "Precision Score        0.588934  0.552679  0.525627  0.536686  0.491483   \n",
       "Recall Score           0.690476  0.677249  0.682540  0.632275  0.701058   \n",
       "Train F1               1.000000  1.000000  1.000000  0.803905  0.614168   \n",
       "Train Precision Score  1.000000  1.000000  1.000000  0.856233  0.530816   \n",
       "Train Recall Score     1.000000  1.000000  1.000000  0.831677  0.728571   \n",
       "\n",
       "                            mlp        rf       svm       xgb  \n",
       "F1                     0.572011  0.584336  0.599316  0.587314  \n",
       "Precision Score        0.534180  0.534168  0.574102  0.687875  \n",
       "Recall Score           0.642857  0.682540  0.666667  0.701058  \n",
       "Train F1               1.000000  0.984329  0.999378  0.941237  \n",
       "Train Precision Score  1.000000  0.984620  0.999379  0.947547  \n",
       "Train Recall Score     1.000000  0.984472  0.999379  0.943478  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_m.to_csv('result_m.csv')\n",
    "result_z.to_csv('result_z.csv')\n",
    "result_p.to_csv('result_p.csv')\n",
    "result_weighted.to_csv('result_weighted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルの予測値を保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 992/1610 [=================>............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Act  dnn3  dnn4  dnn5  dt  lr  mlp  rf  svm  xgb\n",
       "2015-01-02    0     0     0     0   0   0    0   0    0    0\n",
       "2015-01-05   -1     0     0     0   0   0    0   0    0    0\n",
       "2015-01-06    0     0     0     0   0   0    0   0    0    0\n",
       "2015-01-07    1     0     0     0   0   0    0   0    0    0\n",
       "2015-01-08    1     0     0     0   0   0    0   0    0    0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = {}\n",
    "predict_t = {}\n",
    "predict['Act'] = Y\n",
    "predict_t['Act'] = Y_t\n",
    "\n",
    "for s, t in zip(model, model_name):\n",
    "    predict[t]=s.predict(X)\n",
    "    predict_t[t]=s.predict(X_t)\n",
    "\n",
    "for s, t in zip(model_dnn, model_name_dnn):\n",
    "    predict[t]= list(pd.Series(s.predict_classes(X)).map(dnn_map))\n",
    "    predict_t[t]= list(pd.Series(s.predict_classes(X_t)).map(dnn_map))\n",
    "\n",
    "predict = pd.DataFrame(predict, index = df.index)\n",
    "predict_t = pd.DataFrame(predict_t, index = df_t.index)\n",
    "predict.to_csv('predict_test.csv')\n",
    "predict_t.to_csv('predict_train.csv')\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Act</th>\n",
       "      <th>dnn3</th>\n",
       "      <th>dnn4</th>\n",
       "      <th>dnn5</th>\n",
       "      <th>dt</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-08-11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-12</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Act  dnn3  dnn4  dnn5  dt  lr  mlp  rf  svm  xgb\n",
       "2008-08-11    0     0     0     0   0   0    0   0    0    0\n",
       "2008-08-12   -1    -1    -1    -1   0   0   -1  -1   -1   -1\n",
       "2008-08-13    0     0     0     0   0   0    0   0    0    0\n",
       "2008-08-14    0     0     0     0   0   0    0   0    0    0\n",
       "2008-08-15    0     0     0     0   0   0    0   0    0    0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
